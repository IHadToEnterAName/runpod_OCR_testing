# ğŸ³ Complete Docker Deployment - Ready to Run Anywhere!

## ğŸ¯ What You Got

I've created a **complete containerized solution** that runs your entire RAG system in Docker containers. Deploy on **any machine** with just one command!

## ğŸ“¦ Files Included

### 1. **Dockerfile.complete**
Complete Docker image with:
- âœ… NVIDIA CUDA 12.6 (Blackwell sm_120 support)
- âœ… PyTorch nightly (CUDA 12.8)
- âœ… vLLM built from source with RTX 5090 optimization
- âœ… All Python dependencies pre-installed
- âœ… Your refactored code structure

### 2. **docker-compose.complete.yml**
Orchestrates 5 services:
- âœ… **vLLM Vision Server** (Port 8006, GPU 0, 0.3 memory)
- âœ… **vLLM Reasoning Server** (Port 8005, GPU 1, 0.54 memory)
- âœ… **RAG Application** (Port 8000, Chainlit interface)
- âœ… **ChromaDB** (Port 8003, vector database)
- âœ… **Redis** (Port 6379, caching)

### 3. **docker-start.sh**
Interactive control panel:
- âœ… One-click first-time setup
- âœ… Build, start, stop, restart
- âœ… View logs, check status
- âœ… Clean up options
- âœ… Prerequisites checking

### 4. **DOCKER_DEPLOYMENT.md**
Complete documentation:
- âœ… Detailed setup instructions
- âœ… Configuration options
- âœ… Troubleshooting guide
- âœ… Production tips
- âœ… Monitoring commands

### 5. **deploy-one-line.sh**
Automated deployment:
- âœ… Installs Docker if needed
- âœ… Installs NVIDIA runtime
- âœ… Builds images
- âœ… Starts services
- âœ… Shows access URLs

## ğŸš€ Quick Start (3 Steps)

### Option 1: Interactive (Recommended)
```bash
# 1. Make executable
chmod +x docker-start.sh

# 2. Run control panel
./docker-start.sh

# 3. Select: 1) First-time setup
# Wait 15-20 minutes (build + model download)
# Access: http://localhost:8000
```

### Option 2: Manual
```bash
# 1. Build images (10-20 minutes)
docker compose -f docker-compose.complete.yml build

# 2. Start services
docker compose -f docker-compose.complete.yml up -d

# 3. Wait for initialization (5 minutes)
# Watch logs: docker compose -f docker-compose.complete.yml logs -f

# 4. Access: http://localhost:8000
```

### Option 3: One-Line (Automated)
```bash
./deploy-one-line.sh
# Handles everything automatically
```

## ğŸ¯ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Docker Compose Network              â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  RAG App (Port 7860)                 â”‚  â”‚
â”‚  â”‚  - Chainlit UI                       â”‚  â”‚
â”‚  â”‚  - RAG Pipeline                      â”‚  â”‚
â”‚  â”‚  - GPU 0 (embeddings)                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                           â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚     â†“           â†“            â†“             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Vision  â”‚ â”‚Reasoningâ”‚ â”‚ ChromaDB   â”‚   â”‚
â”‚  â”‚ :8006   â”‚ â”‚ :8005   â”‚ â”‚ :8000      â”‚   â”‚
â”‚  â”‚ GPU 0   â”‚ â”‚ GPU 1   â”‚ â”‚ (volumes)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Configuration

### GPU Allocation

**Dual GPU (Default)**:
```yaml
vllm_vision:      device_ids: ['0']  # GPU 0
vllm_reasoning:   device_ids: ['1']  # GPU 1
rag_app:          device_ids: ['0']  # GPU 0
```

**Single GPU**:
Edit `docker-compose.complete.yml`:
```yaml
# Change all to device_ids: ['0']
# Reduce memory:
--gpu-memory-utilization 0.25  # Vision
--gpu-memory-utilization 0.45  # Reasoning
```

### Memory Tuning
```yaml
# Vision server (currently 0.3)
--gpu-memory-utilization 0.3

# Reasoning server (currently 0.54)
--gpu-memory-utilization 0.54

# Adjust based on your GPU VRAM
```

## ğŸ“Š What Gets Containerized

| Component | Container | GPU | Port | Purpose |
|-----------|-----------|-----|------|---------|
| Vision Model | vllm_vision | GPU 0 | 8006 | Image analysis |
| Reasoning Model | vllm_reasoning | GPU 1 | 8005 | Text generation |
| RAG App | rag_app | GPU 0 | 7860 | Chat interface |
| Vector DB | chromadb | - | 8000 | Document search |
| Cache | redis | - | 6379 | Caching layer |

## ğŸ’¾ Persistent Storage

All data persists in `volumes/`:
```
volumes/
â”œâ”€â”€ huggingface/     # Model cache (~20GB)
â”œâ”€â”€ vllm_cache/      # Compiled kernels
â””â”€â”€ models/          # Additional models

data/
â”œâ”€â”€ uploads/         # User uploads
â”œâ”€â”€ processed/       # Processed docs
â””â”€â”€ failed/          # Failed processing
```

**Survives**: Container restarts, rebuilds
**Lost on**: `docker compose down -v` (full cleanup)

## ğŸ® Control Panel Features

Run `./docker-start.sh`:

```
1) First-time setup    â†’ Build + start everything
2) Start services      â†’ Start existing containers
3) Stop services       â†’ Stop all containers
4) Restart services    â†’ Restart containers
5) View logs          â†’ See container output
6) Check status       â†’ Container + GPU status
7) Clean up           â†’ Remove containers
8) Full reset         â†’ Remove everything
9) Exit
```

## ğŸ” Monitoring

### Check Status
```bash
# All services
docker compose -f docker-compose.complete.yml ps

# GPU usage
watch -n 1 nvidia-smi

# Container resources
docker stats
```

### View Logs
```bash
# All services
docker compose -f docker-compose.complete.yml logs -f

# Specific service
docker compose -f docker-compose.complete.yml logs -f vllm_vision
docker compose -f docker-compose.complete.yml logs -f rag_app
```

### Test APIs
```bash
# Vision model
curl http://localhost:8006/v1/models

# Reasoning model
curl http://localhost:8005/v1/models

# ChromaDB
curl http://localhost:8003/api/v1/heartbeat
```

## ğŸ› Troubleshooting

### Build Takes Forever
**Issue**: vLLM compilation is slow
- **Normal**: 10-20 minutes first time
- **Speed up**: Use `--parallel` flag (if supported)
- **Cache**: Second build much faster

### Models Won't Load
**Issue**: OOM or CUDA errors
```bash
# Reduce GPU memory in docker-compose.complete.yml
--gpu-memory-utilization 0.2  # Vision
--gpu-memory-utilization 0.4  # Reasoning

# Restart
docker compose -f docker-compose.complete.yml restart
```

### GPU Not Detected
**Issue**: Containers can't see GPU
```bash
# Test runtime
docker run --rm --gpus all nvidia/cuda:12.6.0-base-ubuntu22.04 nvidia-smi

# If fails, reinstall toolkit:
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

### Port Conflicts
**Issue**: Port already in use
```bash
# Check what's using port
sudo lsof -i :8005

# Change port in docker-compose.complete.yml
ports:
  - "8015:8005"  # External:Internal
```

## ğŸš¢ Deployment Scenarios

### Local Development
```bash
./docker-start.sh
# Select: 1) First-time setup
```

### Remote Server
```bash
# Copy files
scp -r * user@server:/path/to/rag/

# SSH and deploy
ssh user@server
cd /path/to/rag/
./docker-start.sh
```

### Cloud VM (AWS/GCP/Azure)
```bash
# Launch GPU instance
# Install Docker + NVIDIA runtime
# Run deploy-one-line.sh
./deploy-one-line.sh
```

### Kubernetes (Advanced)
```bash
# Convert to K8s manifests
kompose convert -f docker-compose.complete.yml
kubectl apply -f .
```

## ğŸ“ˆ Performance

### Expected Load Times
- **First build**: 15-20 minutes
- **Model download**: 5-10 minutes (20GB)
- **Service startup**: 3-5 minutes
- **Total first run**: ~30 minutes

### After First Run
- **Start services**: 1-2 minutes
- **Model loading**: 30-60 seconds
- **Ready to use**: ~2 minutes

### Response Times
- **First query**: 2-5 seconds (cold start)
- **Subsequent**: 1-3 seconds
- **Cache hit**: N/A (not implemented yet)

## âœ… Success Checklist

After deployment:
- [ ] All containers running: `docker compose ps`
- [ ] No errors in logs: `docker compose logs`
- [ ] GPU visible: `nvidia-smi` inside containers
- [ ] Vision API responds: `curl localhost:8006/v1/models`
- [ ] Reasoning API responds: `curl localhost:8005/v1/models`
- [ ] ChromaDB healthy: `curl localhost:8003/api/v1/heartbeat`
- [ ] Web UI loads: `http://localhost:8000`
- [ ] Can upload documents
- [ ] Can ask questions
- [ ] Responses generated

## ğŸ¯ Benefits

### Portability
- âœ… Run on any Linux with Docker + GPU
- âœ… Same environment everywhere
- âœ… No dependency hell
- âœ… Easy to share/deploy

### Reproducibility
- âœ… Exact same versions
- âœ… Same GPU configuration
- âœ… Same behavior everywhere
- âœ… Version controlled

### Maintainability
- âœ… Easy updates (rebuild image)
- âœ… Easy rollback (use old image)
- âœ… Clear separation (services)
- âœ… Professional setup

### Scalability
- âœ… Add more GPUs (edit device_ids)
- âœ… Run multiple instances
- âœ… Load balance with nginx
- âœ… Kubernetes ready

## ğŸ†š Comparison

### Before (Manual)
```bash
# Multiple terminals
source venv/bin/activate
vllm serve ...  # Terminal 1
vllm serve ...  # Terminal 2
chainlit run    # Terminal 3

# Dependencies
pip install this
pip install that
oh no, version conflict!
```

### After (Docker)
```bash
# One command
./docker-start.sh

# Or
docker compose up -d

# Everything just works!
```

## ğŸ“ Support

### Quick Fixes
1. **Restart**: `docker compose restart`
2. **Rebuild**: `docker compose build --no-cache`
3. **Check logs**: `docker compose logs`
4. **Check GPU**: `nvidia-smi`
5. **Full reset**: `docker compose down -v`

### Get Help
- Check `DOCKER_DEPLOYMENT.md` for details
- View logs: `docker compose logs -f`
- Test APIs: `curl localhost:PORT/v1/models`
- Check status: `docker compose ps`

---

## ğŸ‰ You're Ready!

Your complete RAG system is now:
- âœ… Fully containerized (5 services)
- âœ… GPU optimized (RTX 5090 config)
- âœ… Production ready (health checks, restart policies)
- âœ… Portable (run anywhere with Docker)
- âœ… Easy to manage (control panel)

**Deploy it**:
```bash
./docker-start.sh
# Select: 1
# Wait ~20 minutes
# Open: http://localhost:8000
# Done! ğŸš€
```
