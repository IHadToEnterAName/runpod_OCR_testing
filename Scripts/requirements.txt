# Core ML Framework
torch==2.1.0
torchvision==0.16.0
torchaudio==2.1.0

# Transformers & Embeddings
transformers==4.36.2
sentence-transformers==2.3.1
tiktoken==0.5.2

# LangChain & LangGraph
langchain==0.1.0
langchain-community==0.0.10
langchain-core==0.1.10
langchain-openai==0.0.2
langgraph==0.0.20

# Vector Store
chromadb==0.4.22

# Cache & State
redis==5.0.1
hiredis==2.2.3

# Document Processing
pymupdf==1.23.8
python-docx==1.1.0
pypdf==3.17.4
pillow==10.1.0

# Airflow
apache-airflow==2.8.0
apache-airflow-providers-redis==3.4.0
apache-airflow-providers-postgres==5.10.0

# Web Framework
chainlit==1.0.0
fastapi==0.109.0
uvicorn[standard]==0.27.0

# OpenAI Client (for vLLM)
openai==1.6.1
httpx==0.25.2

# Utilities
numpy==1.24.3
pandas==2.0.3
pydantic==2.5.3
python-dotenv==1.0.0
pyyaml==6.0.1

# Database
psycopg2-binary==2.9.9
sqlalchemy==2.0.25

# Development
pytest==7.4.3
pytest-asyncio==0.21.1
black==23.12.1
flake8==7.0.0



# --- Core Framework & Orchestration ---
chainlit==2.9.4
langgraph==0.2.66
langchain-core==0.3.29

# --- API & Networking ---
httpx==0.28.1
openai==1.59.6

# --- Document Processing & Extraction ---
PyMuPDF==1.26.7
python-docx==1.2.0
langchain-text-splitters==0.3.4

# --- AI & Machine Learning ---
sentence-transformers==3.3.1
tiktoken          # REQUIRED for token counting and context trimming
torch==2.5.1
torchvision       # REQUIRED for Qwen2.5-VL Vision Processing
numpy==2.1.0

# --- vLLM & Blackwell Optimization ---
hf_transfer       # Enables high-speed model downloads
uvloop            # High-performance event loop for vLLM servers
# vllm            # (Installed from source, but listed for reference)

# --- Image Handling ---
Pillow==11.1.0

# --- Typing & Utilities ---
typing-extensions==4.12.2
