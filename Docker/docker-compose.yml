# =============================================================================
# Visual RAG Stack - Docker Compose
# =============================================================================
#
# Services: Redis (cache) + RAG Application (Chainlit + Byaldi)
# vLLM (Qwen3-VL-32B-AWQ) runs on HOST for direct GPU access
# ChromaDB removed - using Byaldi (ColQwen2) for visual retrieval
#
# Usage:
#   1. Start vLLM on host: ./start.sh
#   2. Run: docker-compose up -d
#   3. Access app at http://localhost:8080
#
# =============================================================================

services:
  # ===========================================================================
  # REDIS - Caching Layer
  # ===========================================================================
  redis:
    image: redis:7-alpine
    container_name: rag_redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - ../persistent/redis:/data
    command: redis-server --save 60 1 --loglevel warning --maxmemory 2gb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    networks:
      - rag_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # ===========================================================================
  # RAG APPLICATION - Chainlit + Byaldi (ColQwen2)
  # ===========================================================================
  rag_app:
    build:
      context: ..
      dockerfile: Docker/Dockerfile
    container_name: rag_app
    depends_on:
      redis:
        condition: service_healthy
    environment:
      # Service connections (Docker internal)
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}

      # vLLM endpoint (on HOST machine)
      - VLLM_URL=${VLLM_URL:-http://host.docker.internal:8005/v1}
      - VLLM_MODEL=${VLLM_MODEL:-QuantTrio/Qwen3-VL-32B-Instruct-AWQ}

      # Byaldi model
      - BYALDI_MODEL=${BYALDI_MODEL:-vidore/colqwen2-v0.1}
      - BYALDI_INDEX_PATH=/workspace/data/indexes

      # Visual RAG settings
      - SEARCH_TOP_K=${SEARCH_TOP_K:-10}
      - RERANK_TOP_K=${RERANK_TOP_K:-5}
      - ENABLE_GROUNDING=${ENABLE_GROUNDING:-true}
      - IMAGE_DPI=${IMAGE_DPI:-200}

      # Cache settings
      - CACHE_ENABLED=${CACHE_ENABLED:-true}

      # Routing settings
      - ROUTING_ENABLED=${ROUTING_ENABLED:-true}

      # Generation settings
      - TEMPERATURE=${TEMPERATURE:-0.3}
      - MAX_TOKENS=${MAX_TOKENS:-4096}

      # Hugging Face authentication
      - HF_TOKEN=${HF_TOKEN:-}

      # Python settings
      - PYTHONPATH=/workspace/src
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONUNBUFFERED=1
      - HF_HOME=/workspace/huggingface
      - HF_HUB_ENABLE_HF_TRANSFER=1
      - NVIDIA_VISIBLE_DEVICES=all

      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      # Mount source for development (remove in production)
      - ../src:/workspace/src:ro
      # Chainlit config and public assets
      - ../.chainlit:/workspace/.chainlit:ro
      - ../public:/workspace/public:ro
      # Persistent bind mounts (survive container rebuilds and Docker prune)
      - ../persistent/data:/workspace/data
      - ../persistent/indexes:/workspace/data/indexes
    ports:
      - "${RAG_APP_PORT:-8080}:8000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    dns:
      - 8.8.8.8
      - 8.8.4.4
    runtime: nvidia
    mem_limit: 16g
    restart: unless-stopped
    networks:
      - rag_network

# =============================================================================
# NETWORKS
# =============================================================================
networks:
  rag_network:
    driver: bridge
